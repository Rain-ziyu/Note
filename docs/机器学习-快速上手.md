# 决策树

首先，我们将概述机器学习模型的工作原理及其使用方式。

## 我们假设一个场景：
你的表弟通过房地产投机赚了数百万美元。由于您对数据科学感兴趣，他愿意与您成为业务合作伙伴。他将提供资金，您将提供预测各种房屋价值的模型。
你问你的表弟他过去是如何预测房地产价值的，他说这只是直觉。但更多的询问表明，他从过去看到的房子中确定了价格模式，并使用这些模式来预测他正在考虑的新房子。

机器学习的工作方式相同。 我们将从一个名为 Decision Tree （决策树）的模型开始。有更高级的模型可以给出更准确的预测。但决策树很容易理解，它们是数据科学中最佳模型的基础模块。


为简单起见，我们将从最简单的决策树开始。

![](./images/machineLearn/image.png)

该决策树只将房屋分为两类。每一类中房屋的预测价格是同一类别中房屋的历史平均价格。

我们使用数据来决定如何将房屋分成两组，然后再次确定每组中的预测价格。 从数据中按模式分类的这一步称为拟合或训练模型。用于拟合模型的数据称为训练数据。

模型如何拟合的细节（例如，如何拆分数据）非常复杂，我们将其保存以备后用。拟合模型后，您可以将其应用于新数据以预测其他房屋的价格。

### 改进决策树

![](./images/machineLearn/twotree.png)

以上两个决策树中的哪一个更有可能通过拟合房地产训练数据而产生？

左侧的决策树（决策树 1）可能更有意义，因为它捕捉到了这样一个现实，即卧室较多的房屋往往比卧室较少的房屋售价更高。 该模型的最大缺点是它没有捕捉到影响房价的大多数因素，例如浴室数量、地块大小、位置等。

您可以使用具有更多“拆分”的树来捕获更多因子。这些被称为 “更深” 的树。这个树还考虑每栋房屋地块总大小等。
如下所示：

![](./images/machineLearn/deepertree.png)

您可以通过跟踪决策树来预测任何房屋的价格，始终选择与该房屋特征相对应的路径。房屋的预测价格位于树的底部。 我们进行预测的底部点称为叶子。

叶子上的拆分和值将由数据决定，因此是后续我们将要查看处理数据。

# 随机森林（Random Forests）

决策树往往会带来深度选择的问题。具有大量叶子的深树将过度拟合，因为每个预测仅来自其叶子处的几座房屋的历史数据。但是，叶子很少的浅树性能会很差，因为它无法在原始数据中捕获尽可能多的区别。

即使是当今最复杂的建模技术也面临着欠拟合和过拟合之间的这种紧张关系。但是，许多模型都有自己的解决方法，可以带来更好的性能。我们将以随机森林为例。

随机森林使用许多树，它通过平均每个组件树的预测来做出预测。它通常比单个决策树具有更好的预测准确性，并且默认参数就可以有不错的表现。如果您深入学习建模，您可以学习更多性能更好的模型，但其中许多模型对于参数很敏感。

## 示例

前提：在数据加载结束时，我们定义以下变量：
* train_X 
* val_X 
* train_y 
* val_y 

```python
import pandas as pd
    
# Load data
melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'
melbourne_data = pd.read_csv(melbourne_file_path) 
# Filter rows with missing values
melbourne_data = melbourne_data.dropna(axis=0)
# Choose target and features
y = melbourne_data.Price
melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 
                        'YearBuilt', 'Lattitude', 'Longtitude']
X = melbourne_data[melbourne_features]

from sklearn.model_selection import train_test_split

# split data into training and validation data, for both features and target
# The split is based on a random number generator. Supplying a numeric value to
# the random_state argument guarantees we get the same split every time we
# run this script.
train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)
```


以下代码我们构建一个随机森林模型类似于我们在Scikit -learn中构建决策树的方式类似 - 这次使用RandomForestRegressor类，而不是DecisionTreeRegressor。

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

forest_model = RandomForestRegressor(random_state=1)
forest_model.fit(train_X, train_y)
melb_preds = forest_model.predict(val_X)
print(mean_absolute_error(val_y, melb_preds))
```

最终输出： 191669.7536453626

可能还有进一步改进的空间，但这比最佳决策树最终的的250,000已经有了改进。当我们更改单个决策树的最大深度时，有一些参数使您可以更改随机森林的性能。但是，随机森林模型的最佳特征之一是，即使没有这种调整，它们通常也可以合理地工作。

# 中级机器学习

基于以上两种简单的模型算法的使用我们对如何初步训练一个模型有了简单的了解。
但是实际的模型开发、优化过程中是更复杂的，比如：
* 处理真实数据集中常见的数据类型（缺失值、分类变量），
* 设计管道（pipelines ）以提高机器学习代码的质量，
* 使用高级技术进行模型验证（交叉验证），
* 构建（XGBoost） 的先进模型，以及
* 避免常见和重要的数据科学错误（泄漏）。

## 处理数据缺失值

在实际开发时数据缺失是非常常见的，比如：
两居室的房子不包括第三间卧室的大小值。
调查受访者可以选择不分享其收入。
如果您尝试使用具有缺失值的数据构建模型，大多数机器学习库（包括 scikit-learn）都会出现错误。因此，您需要选择以下三种常见策略之一。

### 1.删除具有缺失值的列

![](./images/machineLearn/Sax80za.png)

这种方法一般不推荐，除非某一列中的大多数都没有值，否则使用此方法将导致模型失去对许多（可能有用的！）信息。 作为一个极端的例子，请考虑一个具有10,000行的数据集，其中一个重要的列中仅缺少一个有效值。这种方法将完全丢弃该列！

### 2.补充缺失值

![](./images/machineLearn/4BpnlPA.png)

使用一些数字填充缺失值。 例如，我们可以为其填充每列平均值。但是这并不是固定的，平均值有时候甚至会不如直接删除缺失列，但这并不代表补充缺失值是更优的，而是我们补充的值不合适，我们可能会采取其他方式来填充值，比如众数等

在大多数情况下，补充的值不会完全正确，但是通常会比完全放弃列获得更准确的模型。

### 3.拓展列然后补充缺失值

补充缺失值是标准方法，通常效果很好。但是，估算的值可能会系统地高于或低于其实际值（该值未收集到数据集中）。或着缺少值的行可能在某种程度上是唯一的。在这种情况下，您的模型将通过考虑最初缺少哪些值来做出更好的预测。
![](./images/machineLearn/UWOyg4a.png)
在这种方法中，我们像以前一样将缺失的值进行估算补充。 此外，对于原始数据集中的每列丢失条目，我们添加了一个新列，以显示该列缺失值。

在某些情况下，这将有意义地改善结果。某些情况下，这也可能无济于事。

## 分类数据

分类变量只采用有限的枚举值，比如：
* 在一项调查中，询问您多久吃一次早餐并提供四个选项：“从不”、“很少”、“大多数日子”或“每天”。 在这种情况下，数据是分类的，因为响应属于一组固定的类别。
* 如果人们回答关于他们拥有哪个品牌的汽车的调查，回答将分为 “本田”、“丰田 ”和 “福特 ”等类别。 在这种情况下，数据也是分类的。

而此时针对这些缺失值我们也需要处理，主要有以下三种方法：

### 删除分类数据列
仅当列不包含有用信息时，此方法才会有效。
### 为分类数据编码（序数编码（Ordinal Encoding））

将每个唯一值分配给不同的整数。
![](./images/machineLearn/tEogUAr.png)
使用此方法我们假定类别的顺序：“从不”（0） < “很少” （1） < “大多数天数” （2） < “每天” （3）。

这个假设在这个例子中是有道理的，因为这些类别有一个比较明显的排名一句。 并非所有分类变量在值中都有明确的排序，因此我们将这些分类变量称为有序变量。 对于基于树的模型（如决策树和随机森林），您可以通过预期序数来为数据编码，一般可以很好地处理序数变量。

### 独热编码

该词直译英文（One-Hot Encoding），独热编码通过创建新列，来指示原始数据中存在（或不存在）每个可能的值。 为了理解这一点，我们将通过一个示例来说明。

![](./images/machineLearn/TW5m0aJ.png)
在原始数据集中，“Color” 是一个分类变量，具有三个类别：“Red”、“Yellow” 和 “Green”。 相应的 one-hot 编码为每个可能的值创建一个新列，原始数据集中的每一行都将被对应起来。 如果原始值为 “Red”，我们在 “Red” 列中放置一个 1;如果原始值为 “Yellow”，则在 “Yellow” 列中输入 1，依此类推。

与Oldinal编码（序数编码）相反，独热编码不假定类别的排序。 因此，如果分类数据中没有明确的排序（例如，“红色”既不是 也不是 ，则可以期望这种方法特别有效。 我们将这种没有内在排名的分类变量称为名义变量）。

但是如果分类变量具有大量枚举值（即，通常不会将其用于变量以上超过15个不同的值），则One-Hot编码通常不能很好地表现。

针对为分类数据编码还存在特殊情况，即有时候训练数据与验证数据由于数据集的影响，两者会具有不同的分类变量，即训练数据中的分类变量少于验证数据，即 训练数据中没有验证数据中的某些分类信息。
测试一般会细分出两种解决方法：
#### 放弃有问题的分类列
以下代码示例可以有效地将训练数据中没有验证数据中的某些分类信息的列打印出来
```python
# Categorical columns in the training data
object_cols = [col for col in X_train.columns if X_train[col].dtype == "object"]

# Columns that can be safely ordinal encoded
good_label_cols = [col for col in object_cols if
                   set(X_valid[col]).issubset(set(X_train[col]))]

# Problematic columns that will be dropped from the dataset
bad_label_cols = list(set(object_cols)-set(good_label_cols))

print('Categorical columns that will be ordinal encoded:', good_label_cols)
print('\nCategorical columns that will be dropped from the dataset:', bad_label_cols)
```
#### 




## 交叉验证

机器学习是一个迭代过程。在这个过程中您将面临以下选择：使用哪些预测变量、使用哪些类型的模型、向这些模型提供哪些参数等。之前我们通过使用验证（或保留）数据来衡量模型质量，以数据驱动的方式做出了这些选择。

但是这种方法也有一些缺点。要体现这一点，假设您有一个包含 5000 行的数据集。您通常会将大约 20% 的数据保留为验证数据集，即 1000 行。但这在确定模型分数时会产生一定的随机性。也就是说，一个模型可能在这一组 1000 行上表现良好，但它在不同的 1000 行上不准确。

在极端情况下，您可以想象验证集中只有 1 行数据。如果您比较所有模型，哪一个模型会对单个数据点做出最佳预测将主要取决于运气！

一般来说，验证集越大，我们衡量模型质量的随机性（又名 “噪声”） 就越少，它就越可靠。但不幸的是，我们只能通过从训练数据中删除行来获得较大的验证集，而较小的训练数据集也意味着更差的模型！

### 什么是交叉验证

在交叉验证中，我们对数据的不同子集运行建模过程，以获得模型质量的多个度量。

例如，我们可以先将数据分成 5 个部分，每个部分占整个数据集的 20%。在本例中，我们已经将数据分成了 5 个 “folds”。
![](./images/machineLearn/9k60cVA.png)

然后，我们为每个组运行一次实验：
* 在实验 1 中，我们使用第一个折叠作为验证（或保留）集，使用其他所有内容作为训练数据。这为我们提供了基于 20% 保留集的模型质量度量。
* 在实验 2 中，我们保留第二个折叠的数据（并使用除第二个折叠之外的所有内容来训练模型）。然后，使用维持集来获取模型质量的第二次估计值。
* 我们重复此过程，将每个弃牌使用一次作为维持集。综上所述，100% 的数据在某个时候被用作保留，我们最终得到了一个基于数据集中所有行的模型质量度量（即使我们没有同时使用所有行）。

### 什么场景下使用交叉验证

交叉验证可以更准确地衡量模型质量，这在您做出大量建模决策时尤为重要。但是，运行时间可能需要更长的时间，因为它会估计多个模型（每个折叠一个模型）。

那么，考虑到这些权衡，何时应该使用该方法呢？
* 对于小型数据集，额外的计算负担并不是什么大问题，此时可以进行交叉验证。
* 对于较大的数据集，单个验证集就足够了。您的代码将运行得更快，并且您可能有足够的数据，因此几乎不需要重用其中一些数据来保持模型可靠性。

对于大型数据集与小型数据集的构成，没有简单的阈值。但是，如果您的模型需要几分钟或更短的时间才能运行，则可能值得切换到交叉验证。

或者，您可以运行交叉验证，并查看每个实验组的分数是否接近。如果每个实验产生相同的结果，则单个验证集可能就足够了。

### 示例

```python
import pandas as pd

# Read the data
data = pd.read_csv('../input/melbourne-housing-snapshot/melb_data.csv')

# Select subset of predictors
cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']
X = data[cols_to_use]

# Select target
y = data.Price
```

然后，我们定义一个管道，该管道使用补充缺失值的方式来解决缺失值，并使用随机森林模型进行预测。

虽然可以在没有管道的情况下进行交叉验证，但这非常困难！使用管道将使代码非常简单。

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),
                              ('model', RandomForestRegressor(n_estimators=50,
                                                              random_state=0))
                             ])
```

在模拟时我们使用 scikit-learn 中的 cross_val_score（） 函数获得交叉验证分数。 我们使用 参数cv 来设置折叠数。

```python


from sklearn.model_selection import cross_val_score

# Multiply by -1 since sklearn calculates *negative* MAE
scores = -1 * cross_val_score(my_pipeline, X, y,
                              cv=5,
                              scoring='neg_mean_absolute_error')

print("MAE scores:\n", scores)

```

上文参数解释：scoring 参数：选择要报告的模型质量度量方式：在本例中，我们选择了**负的**平均绝对误差 （MAE）。在 [scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html) 的文档显示了所有的可选项列表。

我们指定取反的 MAE 有点令人惊讶。scikit-learn 有一个约定，其中定义了所有指标数字越高越好。在这里使用负数可以使它们与该约定保持一致，尽管负 MAE 在其他地方几乎闻所未闻。

我们通常需要单一的模型质量度量方式来比较替代模型。因此，我们取实验的平均值。
### 小结

使用交叉验证可以更好地衡量模型质量，并具有清理代码的额外好处：请注意，我们不再需要跟踪单独的训练集和验证集。因此，特别是对于小型数据集，这是一个很好的改进！

## 梯度提升（Gradient Boosting 、XGBoost）

在之前的大部分内容中，我们都使用随机森林法进行预测，该方法通过对许多决策树的预测求平均值，比单个决策树获得更好的性能。

我们将随机森林法称为 “集成法”的一种。根据定义，集成法结合了多个模型的预测（例如，在随机森林的中是几棵树）。

梯度提升是一种通过循环去迭代的方式将模型添加到集成中的方法。

它首先使用单个模型初始化集成，该模型的预测可能非常离谱。（即使它的预测非常不准确，后续通过在集成模型中继续补充来解决这些错误。）

然后，我们开始循环：

* 首先，我们使用当前集成模型为数据集中的每个观测值生成预测。预测结果是这样生成的，即我们将集成中所有模型的预测相加。
* 将这些预测用于计算损失函数（例如，均方误差）。
* 然后，我们使用 损失函数来拟合新模型并将其添加到集成中。具体来说，我们确定模型参数，以便将这个新模型添加到集成中将减少损失。（旁注：“gradient boosting”中的“gradient”指的是我们将在损失函数上使用梯度下降法来确定这个新模型中的参数。
* 最后，我们将新模型添加到 ensemble 中，然后 一直重复该过程

![](./images/machineLearn/MvCGENh.png)

### 示例

```python
import pandas as pd
from sklearn.model_selection import train_test_split

# Read the data
data = pd.read_csv('../input/melbourne-housing-snapshot/melb_data.csv')

# Select subset of predictors
cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']
X = data[cols_to_use]

# Select target
y = data.Price

# Separate data into training and validation sets
X_train, X_valid, y_train, y_valid = train_test_split(X, y)
```

在后续示例中，我们将使用 XGBoost 库。XGBoost 代表极端梯度提升，这是梯度提升的一种实现，具有一些专注于性能和速度的附加功能。（Scikit-learn 有另一个版本的梯度提升，但 XGBoost 有一些技术优势。）

我们导入 XGBoost 的 scikit-learn API （xgboost.XGBRegressor 的 Exports）。 这允许我们构建和拟合模型，就像我们在 scikit-learn 中所做的那样。 正如您将在输出中看到的那样，XGBRegressor 类具有许多可调参数 -- 您很快就会了解这些参数！

```python
from xgboost import XGBRegressor

my_model = XGBRegressor()
my_model.fit(X_train, y_train)
# 对模型进行预测和评估。
from sklearn.metrics import mean_absolute_error

predictions = my_model.predict(X_valid)
print("Mean Absolute Error: " + str(mean_absolute_error(predictions, y_valid)))
```
### 参数调优

XGBoost 有一些参数会极大地影响准确性和训练速度。您应该了解的第一个参数是：
- n_estimators 
    指定上述建模周期的次数。 它等于我们在集成中包含的模型数量。
    *  值太低会导致欠拟合，从而导致对训练数据和测试数据的预测不准确。
    *  值过高会导致过度拟合，这会导致对训练数据进行准确的预测，但对测试数据的预测不准确（这是我们关心的）。

    典型值范围为 100-1000，但这在很大程度上取决于下面讨论的 learning_rate 参数。

    以下是通过 ensemble 设置模型数量的代码：
    ```python
    my_model = XGBRegressor(n_estimators=500)
    my_model.fit(X_train, y_train)
    ```
- early_stopping_rounds
    early_stopping_rounds 提供了一种自动查找 n_estimators 理想值的方法。early_stopping_rounds会导致模型在验证分数(即用于验证模型表现的方法)停止提高时停止迭代，即使我们没有达到 n_estimators 的硬停止状态。 为 n_estimators 设置一个较高的值，然后使用 early_stopping_rounds 找到停止迭代的最佳时间是明智的。

    由于随机机会有时会导致单轮验证分数没有提高，因此您需要指定一个数字，说明在停止之前允许多少轮直接恶化。 设置 early_stopping_rounds=5 是一个合理的选择。 在这种情况下，我们会在连续 5 轮验证分数恶化后停止。

    使用 early_stopping_rounds 时，您还需要留出一些数据来计算验证分数 - 这是通过设置 eval_set 参数来完成的。

    经验证较新版本的XGBoost将early_stopping_rounds参数放到了XGBRegressor的构造函数中

    下面是我们可以修改上面的示例以应用early_stopping_rounds：
    ```python
        my_model = XGBRegressor(early_stopping_rounds=5, n_estimators=500)
        my_model.fit(X_train, y_train, 
                    
                    eval_set=[(X_valid, y_valid)],
                    verbose=False)
    ```
    以后如果要用所有数据拟合模型，将 n_estimators 设置为在提前停止运行时发现最优的任何值。

- learning_rate

    我们可以将每个模型的预测值乘以一个小数字（称为学习率），然后再将它们相加，而不是简单地将每个组件模型的预测相加来获得预测。
    这意味着我们添加到 ensemble 中的每棵树对我们的帮助较小。 因此，我们可以为 n_estimators 设置更高的值而不会过拟合。 如果我们使用提前停止，将自动确定适当的树木数量。

    一般来说，较小的学习率（learning_rate）和大量的估计器（estimators）将产生更准确的 XGBoost 模型，尽管模型也需要更长的时间来训练，因为它在整个周期中进行更多的迭代。 默认情况下，XGBoost 设置 learning_rate=0.1。

    修改上面的示例以应用学习率参数：
    ```python
    my_model = XGBRegressor(early_stopping_rounds=5, n_estimators=1000, learning_rate=0.05)
    my_model.fit(X_train, y_train, 
                eval_set=[(X_valid, y_valid)], 
                verbose=False)
    ```
- n_jobs

    在考虑运行时的较大数据集上，您可以使用并行性来更快地构建模型。 通常将参数 n_jobs 设置为等于计算机上的内核数。 对于较小的数据集，这无济于事。
    生成的模型不会更好，因此对拟合时间进行微调通常只会分散注意力。但是，它在大型数据集中非常有用，否则您将花费很长时间等待 fit 命令。
    以下是修改后的示例：
    ```python
    my_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)
    my_model.fit(X_train, y_train, 
                early_stopping_rounds=5, 
                eval_set=[(X_valid, y_valid)], 
                verbose=False)
    ```
### 总结
XGBoost 是一个领先的软件库，用于处理标准表格数据（您存储在 Pandas DataFrames 中的数据类型，而不是图像和视频等更奇特的数据类型）。通过仔细的参数调整，您可以训练高度准确的模型。
