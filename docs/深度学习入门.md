# 深度学习入门

近年来，人工智能领域一些最令人印象深刻的进步就是在深度学习领域。深度学习模型在自然语言翻译（Natural Language Translation）、图像识别（Image Recognition）和游戏博弈（Game Playing）等领域已经达到甚至超越人类水平的表现。

那么什么是深度学习呢？

深度学习是机器学习的一个分支，其核心特征是通过**多层（“深度”）计算堆叠来学习数据**的复杂表征。这种深度计算结构使深度学习模型能够解析现实世界数据中错综复杂的层级化模式（如图像的边缘→纹理→物体部件→完整物体，或语言的音素→单词→句子→语义），从而在诸多任务上取得突破性表现。

其中多层（“深度”）计算堆叠来学习数据指的是：    模型由多个非线性变换层（如全连接层、卷积层、注意力层）堆叠而成，每一层逐步提取更高层次的抽象特征。例如：图像识别中，浅层可能检测边缘，深层可能识别物体类别。

神经网络通过其强大的连接复杂性和可扩展性，成为深度学习的标志性模型。尽管单个神经元仅执行简单计算，但大量神经元通过多层次、高灵活性的互联，能够学习数据中极其复杂的模式。

深度学习简单来说就是为了解决在机器学习中的特征工程问题。深度学习通过构建多层神经网络来自动提取特征，从而减少了对人工特征工程的依赖。

往往大家会讲深度学习过程当成一个黑盒子，这也是因为深度学习的内部逻辑是非常复杂的。实际上深度学习的核心就是神经网络。神经网络是由大量的神经元（节点）组成的，每个神经元通过连接权重与其他神经元相连。通过调整这些权重，神经网络可以学习到输入数据的特征，从而进行分类、回归等任务。

使用 Keras 和 Tensorflow，学习如何进行：
* 创建**完全连接**的神经网络架构 
    （ 也称为 Dense Layer（密集层） 或 Linear Layer（线性层）。每一层的 每个神经元 都与下一层的 所有神经元 相连。例如：如果第 1 层有 3 个神经元，第 2 层有 2 个神经元，那么它们之间的连接权重矩阵就是 3×2 大小，该矩阵用于后续进行层与层，神经元之间的权重。）
* 运用神经网络解决经典的**回归与分类问题**
* 使用随机梯度下降法训练神经网络
* 使用 dropout、批量归一化和其他技术来提高性能。

## 线性单元

让我们从神经网络的基本组件开始：单个神经元。如图所示，具有一个输入的神经元（或单元）如下所示：
![](./images/deepLearn/mfOlDR6.png)

输入为 x。它与神经元的连接有一个权重，即 w。每当值流经连接时，您都会将该值乘以连接的权重。对于输入 x，到达神经元的是 w * x。神经网络通过修改其权重来“学习”。我们也常称这一个线性单元为**线性函数**。

b 是一种特殊的权重，我们称之为 bias（偏差）。偏差没有任何与之关联的输入数据;相反，我们在图中放置一个 1，这样到达神经元的值就是 b（因为 1 * b = b）。偏差使神经元能够独立于其输入修改输出。
y 是神经元最终输出的值。为了获得输出，神经元将它通过其连接接收到的所有值相加。这个神经元的激活是 y = w * x + b，或者作为公式 y=wx+by=wx+by = w x + b。
### 线性函数：

用于计算一个数据在每一个类别上的最终得分

f(x,W) = W* x+b 

其中W表示每一个数据点（将一个数据分成多个部分作为基本单元进行计算）对应的权重系数，x表示所有数据点对应的值，b表示每一种分类计算值是需要的浮动量。

下图是以一张图片为例，图片粗略的分为四个像素点，实际上像素点肯定更多，然后这是一个三分类的示例。
![](./images/deepLearn/image.png)

### 线性函数计算过程示例；
尽管单个神经元通常仅作为更大网络的一部分发挥作用，但从单个神经元模型作为基础开始学习通常很有用。单神经元模型其实就是线性模型。
让我们以"80种谷物"数据集为例来理解这个过程。假设我们训练一个模型，以"含糖量"（每份糖的克数）作为输入，"卡路里"（每份的热量）作为输出，最终得到模型的偏置项b=90，权重w=2.5。那么对于一份含5克糖的谷物，我们可以这样估算其卡路里含量：
![](./images/deepLearn/yjsfFvY.png)
而且，根据我们的公式，我们有 calories = 2.5 × 5 + 90 = 102.5 卡路里=2.5×5+90=102.5 ，正如我们预期的那样。

### 多个输入
上文使用的卡路里数据集其中有很多其他特征不仅仅是含糖量。如果我们想扩展我们的模型以包括纤维或蛋白质含量等内容，该怎么办？这很简单。我们可以向神经元添加更多的输入连接，每个额外的特征对应一个连接权重。具体计算时，我们将每个输入乘以其连接权重，然后将它们全部相加。
![](./images/deepLearn/vyXSnlZ.png)

这个神经元最终的公式是 `y=w0*x0+w1*x1+w2*x2+b`.具有两个输入的线性单元将拟合一个二维平面，而具有多个输入的单元将拟合一个多维超平面。

### Keras中的线性单元
在 Keras 中创建模型的最简单方法是通过 keras.Sequential，它将神经网络创建为层堆栈。我们可以使用 dense 层创建上述模型（我们将在下一课中详细介绍）。

我们可以定义一个线性模型，接受三个输入特征（'sugars'、'fiber' 和 'protein'）并产生一个输出 （'calories'），如下所示：
```python
from tensorflow import keras
from tensorflow.keras import layers

# Create a network with 1 linear unit
model = keras.Sequential([
    layers.Dense(units=1, input_shape=[3])
])
```

第一个参数 units，用于定义我们想要多少个输出。在这种情况下，我们只预测 'calories'，因此我们将使用 units=1。
第二个参数 input_shape，我们告诉 Keras 输入的维度。设置 input_shape=[3] 可确保模型接受三个特征作为输入（'sugars'、'fiber' 和 'protein'）。

一个简单的神经单元模型就建立完成了。

> 为什么input_shape是一个 Python 列表？
> 我们将在后续演示中使用的数据将是表格数据，就像在 Pandas dataframe中一样。数据集中的每个特征都有一个输入。特征按列排列，因此我们需要使用 input_shape=[num_columns] Keras 在此处使用列表的原因是允许使用更复杂的数据集。例如，图像数据可能需要三个维度：[height, width, channels]


Keras 使用张量存储网络所有权重参数，其本质是 TensorFlow 优化的多维数组（类似 NumPy 数组但更强大） 

模型的权重作为张量列表保存在其 weights 属性中。获取您在上面定义的模型的权重。（如果需要，您可以使用类似以下内容来显示权重：
```python
# YOUR CODE HERE
w, b = model.weights
print("Weights\n{}\n\nBias\n{}".format(w, b))
# Check your answer
q_3.check()
```
![](./images/deepLearn/1748440903971.png)
与 NumPy 数组的关键区别

| 特性         | NumPy 数组     | TensorFlow 张量               |
|--------------|----------------|-------------------------------|
| **硬件加速** | 仅 CPU         | 支持 GPU/TPU                 |
| **自动微分** | 不支持         | 原生支持 (`GradientTape`)    |
| **分布式计算**| 手动实现       | 原生并行化                   |
| **计算图优化**| 无             | XLA 编译器优化               |

需要注意的是在训练之前，模型的权重是随机设置的。运行下面的单元格几次，以查看不同行生成的的随机初始化权重值。
```python
import tensorflow as tf
import matplotlib.pyplot as plt

model = keras.Sequential([
    layers.Dense(1, input_shape=[1]),
])

x = tf.linspace(-1.0, 1.0, 100)
y = model.predict(x)

plt.figure(dpi=100)
plt.plot(x, y, 'k')
plt.xlim(-1, 1)
plt.ylim(-1, 1)
plt.xlabel("Input: x")
plt.ylabel("Target y")
w, b = model.weights # you could also use model.get_weights() here
plt.title("Weight: {:0.2f}\nBias: {:0.2f}".format(w[0][0], b[0]))
plt.show()
```
![](./images/deepLearn/1748440853705.png)
## 深度神经网络

在本节中，我们将探索如何构建能够学习深度神经网络所擅长的复杂关系的神经网络。

这里的关键思想是模块化，从更简单的功能单元构建一个复杂的网络。我们之前已经了解了线性单元如何计算线性函数 -- 现在我们将了解如何组合和修改这些单个单元来模拟更复杂的关系。

### Layers 层

神经网络通常将其神经元组织成层。当我们将具有一组公共输入的线性单元收集在一起时，我们会得到一个密集层。

下图是一个由两个线性单元组成的密集层，接收两个输入和一个偏差。
![](./images/deepLearn/2MA4iMV.png)

您可以将神经网络中的每一层都视为执行某种相对简单的转换。通过深层堆栈，神经网络可以以越来越复杂的方式转换其输入。在训练有素的神经网络中，每一层都是一个转换，让我们更接近一个解决方案。

> 多种多样的层
> 在 Keras 中，“层”是一种非常通用的东西。从本质上讲，层可以是任何类型的数据转换。许多层，如卷积层和递归层，通过使用神经元来转换数据，主要区别在于它们形成的连接模式。其他 API 使用特征工程或仅进行简单的算术。这一个充满各种层次的世界等着你去发现 - 快来看看吧！

### 激活函数

然而，事实证明，两个中间没有任何内容的密集层并不比单个密集层本身好。密集的图层本身永远无法让我们走出线条和平面的世界。我们需要的是非线性的东西。也就是激活函数。

可以说如果没有激活函数，神经网络只能学习线性关系。为了拟合曲线，我们需要使用激活函数。
![](./images/deepLearn/OLSUEYT.png)

激活函数只是我们应用于层的每个输出（其激活）的某个函数。最常见的是max(0,x) 整流器函数.

![](./images/deepLearn/aeIyAlF.png)

整流函数的图形是一条直线，但负值部分会被"修正"为零。将这个函数应用于神经元的输出时，会在数据中产生一个转折点，从而使我们摆脱简单的线性关系。

当我们将整流器连接到线性单元时，我们会得到一个整流线性单元或 ReLU。（因此，通常将整流器函数称为“ReLU 函数”。 将 ReLU 激活应用于线性单元意味着输出变为 max(0, w * x + b)，我们可以将其绘制成下图：
![](./images/machineLearn/eFry7Yu.png)

### 堆叠全连接层
现在我们已经了解了一些非线性的特征，让我们看看如何堆叠层来获得复杂的数据转换。
下图是一个结构示例：堆叠全连接层 即构成"全连接网络"
![](./images/deepLearn/Y5iwFQZ.png)

输出层之前的层有时被称为隐藏层，因为我们无法直接看到它们的输出。

需要注意的是，上图中的最终 （输出） 层是一个线性单元 （意味着没有激活函数）。这使得这个网络适合于回归任务，用于试图预测一些可以是任意的数值任务。其他任务（如分类）可能需要对输出执行激活函数。

### Building Sequential Models （构建 Sequential 模型）

我们一直在使用的 Sequential 模型将按从头到尾的顺序将一系列层连接在一起：第一层获得输入，最后一层产生输出。下面是对应模型的代码示例：
```python
from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([
    # the hidden ReLU layers
    layers.Dense(units=4, activation='relu', input_shape=[2]),
    layers.Dense(units=3, activation='relu'),
    # the linear output layer 
    layers.Dense(units=1),
])
```
需要注意的是，所有的层是放到一个列表中，例如
```python
[
    # the hidden ReLU layers
    layers.Dense(units=4, activation='relu', input_shape=[2]),
    layers.Dense(units=3, activation='relu'),
    # the linear output layer 
    layers.Dense(units=1),
]
```
而不是作为单独的参数。要配置层使用的激活函数，只需在层中添加一个 activation 参数即可。对于输出层，我们不需要激活函数，因为我们正在执行回归任务。

## 随机梯度下降法

之前我们学习了如何通过堆叠全连接层来构建全连接网络。网络首次创建时，网络的所有权重都是随机设置的 -- 网络还一无所知。在本节中，我们将了解如何训练神经网络，了解观察神经网络的学习过程。

与所有机器学习任务一样，我们从一组训练数据开始。训练数据中的每个样本都包含一些特征 （输入） 和预期目标 （输出）。训练神经网络其实就是调整其权重，使其能够将特征转换为目标。例如，在 80 个谷物数据集中，我们想要得到一个神经网络，它可以获取每种谷物的 'sugar'、'fiber' 和 'protein' 含量，并对该谷物的 'calories' 产生预测。如果我们能成功地训练一个网络来做到这一点，那么它的权重必须以某种方式表示这些特征与训练数据中表达的目标之间的关系。

除了训练数据之外，我们还需要两样东西：
* 一个 “损失函数”，用于衡量网络预测的好坏。
* 一个 “优化器” ，可以告诉网络如何更改其权重。

### 损失函数

我们已经了解了如何设计神经网络架构，但还没有了解如何告诉网络要解决什么问题。这就是损失函数的工作。